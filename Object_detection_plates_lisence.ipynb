{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bqQnFmrURPHG",
        "outputId": "a2b07edb-dd52-4a46-910d-2f6c4a3638c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.111-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.111-py3-none-any.whl (978 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m978.8/978.8 kB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m109.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.111 ultralytics-thop-2.0.14\n",
            "Collecting deep-sort-realtime\n",
            "  Downloading deep_sort_realtime-1.3.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dotenv\n",
            "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
            "Collecting anthropic\n",
            "  Downloading anthropic-0.49.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deep-sort-realtime) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from deep-sort-realtime) (1.14.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from deep-sort-realtime) (4.11.0.86)\n",
            "Collecting python-dotenv (from dotenv)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (2.11.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.0)\n",
            "Downloading deep_sort_realtime-1.3.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
            "Downloading anthropic-0.49.0-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv, dotenv, deep-sort-realtime, anthropic\n",
            "Successfully installed anthropic-0.49.0 deep-sort-realtime-1.3.2 dotenv-0.9.9 python-dotenv-1.1.0\n",
            "Collecting azure-cognitiveservices-vision-computervision\n",
            "  Downloading azure_cognitiveservices_vision_computervision-0.9.1-py2.py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting msrest>=0.6.21 (from azure-cognitiveservices-vision-computervision)\n",
            "  Downloading msrest-0.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting azure-common~=1.1 (from azure-cognitiveservices-vision-computervision)\n",
            "  Downloading azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting azure-core>=1.24.0 (from msrest>=0.6.21->azure-cognitiveservices-vision-computervision)\n",
            "  Downloading azure_core-1.33.0-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from msrest>=0.6.21->azure-cognitiveservices-vision-computervision) (2025.1.31)\n",
            "Collecting isodate>=0.6.0 (from msrest>=0.6.21->azure-cognitiveservices-vision-computervision)\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from msrest>=0.6.21->azure-cognitiveservices-vision-computervision) (2.0.0)\n",
            "Requirement already satisfied: requests~=2.16 in /usr/local/lib/python3.11/dist-packages (from msrest>=0.6.21->azure-cognitiveservices-vision-computervision) (2.32.3)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from azure-core>=1.24.0->msrest>=0.6.21->azure-cognitiveservices-vision-computervision) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from azure-core>=1.24.0->msrest>=0.6.21->azure-cognitiveservices-vision-computervision) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests~=2.16->msrest>=0.6.21->azure-cognitiveservices-vision-computervision) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests~=2.16->msrest>=0.6.21->azure-cognitiveservices-vision-computervision) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests~=2.16->msrest>=0.6.21->azure-cognitiveservices-vision-computervision) (2.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-cognitiveservices-vision-computervision) (3.2.2)\n",
            "Downloading azure_cognitiveservices_vision_computervision-0.9.1-py2.py3-none-any.whl (36 kB)\n",
            "Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
            "Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_core-1.33.0-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.1/207.1 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: azure-common, isodate, azure-core, msrest, azure-cognitiveservices-vision-computervision\n",
            "Successfully installed azure-cognitiveservices-vision-computervision-0.9.1 azure-common-1.1.28 azure-core-1.33.0 isodate-0.7.2 msrest-0.7.1\n",
            "Requirement already satisfied: azure-cognitiveservices-vision-computervision in /usr/local/lib/python3.11/dist-packages (0.9.1)\n",
            "Requirement already satisfied: msrest>=0.6.21 in /usr/local/lib/python3.11/dist-packages (from azure-cognitiveservices-vision-computervision) (0.7.1)\n",
            "Requirement already satisfied: azure-common~=1.1 in /usr/local/lib/python3.11/dist-packages (from azure-cognitiveservices-vision-computervision) (1.1.28)\n",
            "Requirement already satisfied: azure-core>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from msrest>=0.6.21->azure-cognitiveservices-vision-computervision) (1.33.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from msrest>=0.6.21->azure-cognitiveservices-vision-computervision) (2025.1.31)\n",
            "Requirement already satisfied: isodate>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from msrest>=0.6.21->azure-cognitiveservices-vision-computervision) (0.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from msrest>=0.6.21->azure-cognitiveservices-vision-computervision) (2.0.0)\n",
            "Requirement already satisfied: requests~=2.16 in /usr/local/lib/python3.11/dist-packages (from msrest>=0.6.21->azure-cognitiveservices-vision-computervision) (2.32.3)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from azure-core>=1.24.0->msrest>=0.6.21->azure-cognitiveservices-vision-computervision) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from azure-core>=1.24.0->msrest>=0.6.21->azure-cognitiveservices-vision-computervision) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests~=2.16->msrest>=0.6.21->azure-cognitiveservices-vision-computervision) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests~=2.16->msrest>=0.6.21->azure-cognitiveservices-vision-computervision) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests~=2.16->msrest>=0.6.21->azure-cognitiveservices-vision-computervision) (2.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-cognitiveservices-vision-computervision) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics\n",
        "!pip install deep-sort-realtime dotenv anthropic\n",
        "!pip install azure-cognitiveservices-vision-computervision\n",
        "!pip install --upgrade azure-cognitiveservices-vision-computervision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k25y_3PzOFY-",
        "outputId": "ec57f8f0-5b28-4aee-de66-2d84a6a33db9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWQuhfXHS1KB",
        "outputId": "ea3485d7-0064-408d-bb05-0c7565e76e04"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"/content/API Key.env\")\n",
        "load_dotenv(dotenv_path=\"/content/API Key.env\", override=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGDR4SMkMfue",
        "outputId": "fe77836b-d9cc-4476-b0e5-22e772116692"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Apr  8 13:30:26 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0             45W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8Ykj42-eQ6aS",
        "outputId": "93acec5c-f687-48e6-9dd7-ef7775940c0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO(\"/content/results_version_3/content/runs/detect/train2/weights/best.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJP7kUT8PT1J",
        "outputId": "b538ac92-288b-4ef9-cc25-a817da7d57d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'car',\n",
              " 1: 'cross_walk',\n",
              " 2: 'green_lights',\n",
              " 3: 'lisence_plate',\n",
              " 4: 'motorcycle',\n",
              " 5: 'nothing',\n",
              " 6: 'red_lights'}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results[0].names"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Extract lisence plate**"
      ],
      "metadata": {
        "id": "TNcm7uiL5yRI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDH5DCDF0oj8"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "from PIL import Image\n",
        "from google import genai\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "from google.genai import types\n",
        "import pathlib\n",
        "import PIL.Image\n",
        "import requests\n",
        "import anthropic\n",
        "\n",
        "\n",
        "class ExtractLicensePlates:\n",
        "    def __init__(self, image):\n",
        "        self.original_image = image\n",
        "        self._init_azure_client()\n",
        "        self._init_gemini_client()\n",
        "        self._init_claude_client()\n",
        "        self.image = self._ensure_image_path(image)\n",
        "\n",
        "    def _init_azure_client(self):\n",
        "        endpoint = \"https://tamhuynh278.cognitiveservices.azure.com/\"\n",
        "        key = os.getenv(\"AZURE_OCR\")\n",
        "        self.azure_client = ComputerVisionClient(\n",
        "            endpoint,\n",
        "            CognitiveServicesCredentials(key)\n",
        "        )\n",
        "\n",
        "    def _init_gemini_client(self):\n",
        "        from google import genai\n",
        "        gemini_key = os.getenv(\"GEMINI_API_KEY\")\n",
        "        self.gemini_client = genai.Client(api_key = gemini_key)\n",
        "\n",
        "    def _init_claude_client(self):\n",
        "        claude_key = os.getenv(\"CLAUDE_API_KEY_TON\")\n",
        "        self.claude_client = anthropic.Anthropic(api_key=claude_key)\n",
        "\n",
        "    def _ensure_image_path(self, image):\n",
        "        if isinstance(image, str):\n",
        "            return image\n",
        "\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "        enhanced = clahe.apply(gray)\n",
        "        output_path = os.path.abspath(\"new.jpg\")\n",
        "        cv2.imwrite(output_path, enhanced)\n",
        "\n",
        "        return output_path\n",
        "\n",
        "    def extract_text_with_plate_recogniation(self):\n",
        "        try:\n",
        "            with open(self.image, 'rb') as fp:\n",
        "                response = requests.post(\n",
        "                    'https://api.platerecognizer.com/v1/plate-reader/',\n",
        "                    files=dict(upload=fp),\n",
        "                    headers={'Authorization': f'Token {os.getenv(\"PLATES_RECOGNI\")}'}\n",
        "                )\n",
        "\n",
        "                if response.status_code == 201:\n",
        "                    result = response.json()\n",
        "                    for res in result['results']:\n",
        "                        return res['plate'].upper()\n",
        "                else:\n",
        "                    return response.status_code, response.text\n",
        "        except Exception as e:\n",
        "            return None\n",
        "\n",
        "\n",
        "    def extract_text_with_azure(self):\n",
        "        try:\n",
        "            with open(self.image , \"rb\") as image_stream:\n",
        "                read_response = self.azure_client.read_in_stream(image_stream, raw=True)\n",
        "            operation_location = read_response.headers[\"Operation-Location\"]\n",
        "            operation_id = operation_location.split(\"/\")[-1]\n",
        "\n",
        "            while True:\n",
        "                result = self.azure_client.get_read_result(operation_id)\n",
        "                if result.status.lower() not in [\"notstarted\", \"running\"]:\n",
        "                    break\n",
        "                time.sleep(1)\n",
        "\n",
        "            if result.status == \"succeeded\":\n",
        "                extracted_text = []\n",
        "                if hasattr(result, 'analyze_result') and hasattr(result.analyze_result, 'read_results'):\n",
        "                    for page in result.analyze_result.read_results:\n",
        "                        for line in page.lines:\n",
        "                            extracted_text.append(line.text)\n",
        "                    return \"\\n\".join(extracted_text) if extracted_text else None\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            return None\n",
        "\n",
        "    def extract_text_with_claude(self):\n",
        "        try:\n",
        "            system_prompt = \"\"\"\n",
        "            You are an OCR engine specialized in reading license plates from images.\n",
        "\n",
        "            Your task:\n",
        "            - Extract the license plate only.\n",
        "            - Return only the license plate as a single line of plain text.\n",
        "            - Do not include any explanations, apologies, or additional messages.\n",
        "            - If the license plate cannot be identified, return only: \"unknown\"\n",
        "            - Output should never include phrases like \"The extracted license plate is...\" or \"Unable to extract...\n",
        "            \"\"\"\n",
        "\n",
        "            message_list = [\n",
        "                {\n",
        "                    \"role\": 'user',\n",
        "                    \"content\": [\n",
        "                        {\"type\": \"image\", \"source\": {\"type\": \"base64\", \"media_type\": \"image/jpeg\", \"data\": get_base64_encoded_image(self.image)}},\n",
        "                        {\"type\": \"text\", \"text\": system_prompt}\n",
        "                    ]\n",
        "                }\n",
        "            ]\n",
        "\n",
        "            response = self.claude_client.messages.create(\n",
        "                model=\"claude-3-haiku-20240307\",\n",
        "                max_tokens=600,\n",
        "                messages=message_list\n",
        "                )\n",
        "            return response.content[0].text\n",
        "\n",
        "        except Exception as e:\n",
        "            return None\n",
        "\n",
        "    def extract_text_with_gemini(self):\n",
        "        from google import genai\n",
        "\n",
        "        try:\n",
        "            system_prompt = \"\"\"\n",
        "            You are an OCR engine specialized in reading license plates from images.\n",
        "\n",
        "            Your task:\n",
        "            - Extract the license plate only.\n",
        "            - Return only the license plate as a single line of plain text.\n",
        "            - Do not include any explanations, apologies, or additional messages.\n",
        "            - If the license plate cannot be identified, return only: \"unknown\"\n",
        "            - Output should never include phrases like \"The extracted license plate is...\" or \"Unable to extract...\"\n",
        "            \"\"\"\n",
        "            b64_image = types.Part.from_bytes(\n",
        "                data=pathlib.Path(self.image).read_bytes(),\n",
        "                mime_type=\"image/jpeg\"\n",
        "            )\n",
        "            response = self.gemini_client.models.generate_content(\n",
        "                model=\"gemini-1.5-pro\",\n",
        "                contents=[system_prompt, b64_image ])\n",
        "            return response.text\n",
        "        except Exception as e:\n",
        "            return None\n",
        "\n",
        "    def analyze_plates(self, text_list):\n",
        "        clean_text = []\n",
        "        for text in text_list:\n",
        "            if isinstance(text, str):\n",
        "                clean_text.append(text)\n",
        "            elif isinstance(text, list):\n",
        "                clean_text.extend([str(item) for item in text])\n",
        "            elif isinstance(text, tuple):\n",
        "                continue\n",
        "            elif isinstance(i, dict):\n",
        "                continue\n",
        "            else:\n",
        "                clean_text.append(str(text))\n",
        "\n",
        "        clean_text = \"\\n\".join(clean_text)\n",
        "        try:\n",
        "            system_prompt = \"\"\"\n",
        "                You are a helpful AI assistant.\n",
        "                - Extract the **best matching license plate**, even if it is **incomplete**.\n",
        "                - Prioritize strings that follow **partial or full plate formats**, such as:\n",
        "                - Motorcycles: XXXX XXXXX (examples: 43E1 16480, 72A2 02501, ....)\n",
        "                - Cars: XXX XXXXX (examples: 29A 12345, 50C 75820, ....)\n",
        "                - Please remember to put a space for me\n",
        "\n",
        "                Instructions:\n",
        "                - Return **only** the most likely license plate string.\n",
        "                - Return only the license plate as a single line of plain text.\n",
        "                - Do not include any explanations, apologies, or additional messages.\n",
        "                \"\"\"\n",
        "\n",
        "            response = self.claude_client.messages.create(\n",
        "                model=\"claude-3-haiku-20240307\",\n",
        "                max_tokens=100,\n",
        "                system=system_prompt,\n",
        "                messages=[{\"role\": \"user\", \"content\": clean_text}]\n",
        "            )\n",
        "            return response.content[0].text\n",
        "        except Exception as e:\n",
        "            return None\n",
        "\n",
        "\n",
        "    def run_method_OCR(self):\n",
        "        extracted_text = self.extract_text_with_plate_recogniation()\n",
        "        if extracted_text:\n",
        "            return extracted_text\n",
        "\n",
        "        extracted_text = self.extract_text_with_claude()\n",
        "        if extracted_text:\n",
        "            return extracted_text\n",
        "\n",
        "        extracted_text = self.extract_text_with_azure()\n",
        "        if extracted_text:\n",
        "            return extracted_text\n",
        "\n",
        "        extracted_text = self.extract_text_with_gemini()\n",
        "        if extracted_text:\n",
        "            return extracted_text\n",
        "\n",
        "        if not extracted_text:\n",
        "            return \"UNKNOWN\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Logic handle and draw stopline**"
      ],
      "metadata": {
        "id": "RXNwHUXu578T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qANwxM_s1xUz"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def is_vehicle_crossed_stop_line(vehicle_bbox, stop_line):\n",
        "    _, _, x2, y2 = vehicle_bbox\n",
        "    return y2 >= stop_line[\"y\"] and stop_line[\"x_min\"] <= x2 <= stop_line[\"x_max\"]\n",
        "\n",
        "\n",
        "def create_stop_line_from_crosswalk(crosswalk_bbox, offset=10, min_length=50):\n",
        "    x1, y1, x2, y2 = crosswalk_bbox\n",
        "    stop_line_y = y1 - offset\n",
        "\n",
        "    length = x2 - x1\n",
        "    if length < min_length:\n",
        "        center = (x1 + x2)/2\n",
        "        x1 = center - min_length/2\n",
        "        x2 = center + min_length/2\n",
        "    return {\"y\": stop_line_y, \"x_min\": int(x1), \"x_max\": int(x2)}\n",
        "\n",
        "\n",
        "\n",
        "def draw_stop_line(frame, stop_line, thickness=2):\n",
        "    cv2.line(frame,\n",
        "             (int(stop_line[\"x_min\"]), int(stop_line[\"y\"])),\n",
        "             (int(stop_line[\"x_max\"]), int(stop_line[\"y\"])),\n",
        "             (0, 0, 255),\n",
        "             thickness)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoDQYeq1PEYQ"
      },
      "outputs": [],
      "source": [
        "def is_valid_plate_flexible(plate_bbox, vehicle_bbox,\n",
        "                          min_iou_ratio=0.2,\n",
        "                          max_edge_margin=20,\n",
        "                          bottom_height_ratio=0.7):\n",
        "\n",
        "    inter_x1 = max(plate_bbox[0], vehicle_bbox[0])\n",
        "    inter_y1 = max(plate_bbox[1], vehicle_bbox[1])\n",
        "    inter_x2 = min(plate_bbox[2], vehicle_bbox[2])\n",
        "    inter_y2 = min(plate_bbox[3], vehicle_bbox[3])\n",
        "\n",
        "    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)\n",
        "    plate_area = (plate_bbox[2] - plate_bbox[0]) * (plate_bbox[3] - plate_bbox[1])\n",
        "    iou = inter_area / plate_area if plate_area > 0 else 0\n",
        "\n",
        "    left_close = abs(plate_bbox[0] - vehicle_bbox[0]) <= max_edge_margin\n",
        "    right_close = abs(plate_bbox[2] - vehicle_bbox[2]) <= max_edge_margin\n",
        "\n",
        "    plate_center_y = (plate_bbox[1] + plate_bbox[3]) / 2\n",
        "    vehicle_bottom = vehicle_bbox[1] + (vehicle_bbox[3] - vehicle_bbox[1]) * bottom_height_ratio\n",
        "    is_at_bottom = plate_center_y >= vehicle_bottom\n",
        "\n",
        "    return (iou >= min_iou_ratio or left_close or right_close) and is_at_bottom"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pipeline object detections**"
      ],
      "metadata": {
        "id": "6QtiMbm_5iGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ObjectDetector:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.red_lights = []\n",
        "        self.motorcycles = []\n",
        "        self.cars = []\n",
        "        self.vehicles = []\n",
        "        self.cross_walks = []\n",
        "        self.lisence_plates = []\n",
        "        self.dets = []\n",
        "\n",
        "    def detect_objects(self, image):\n",
        "        results = self.model(image)\n",
        "        detections = results[0].boxes.data.cpu().numpy()\n",
        "\n",
        "        CONF_THRESHOLDS = {0: 0.4, 1: 0.3, 3: 0.6, 4: 0.4}\n",
        "\n",
        "        for det in detections:\n",
        "            x1, y1, x2, y2, conf, cls = det\n",
        "            cls = int(cls)\n",
        "\n",
        "            if cls in CONF_THRESHOLDS and conf < CONF_THRESHOLDS[cls]:\n",
        "                continue\n",
        "\n",
        "            if cls in [0, 4]:\n",
        "                width = x2 - x1\n",
        "                height = y2 - y1\n",
        "                self.vehicles.append(([x1, y1, width, height], conf, cls))\n",
        "\n",
        "            if cls in [3, 6]:\n",
        "                width = x2 - x1\n",
        "                height = y2 - y1\n",
        "                self.dets.append(([x1, y1, width, height], conf, cls))\n",
        "\n",
        "            if cls == 3:\n",
        "                self.lisence_plates.append([x1, y1, x2, y2])\n",
        "            elif cls == 0:\n",
        "                self.motorcycles.append([x1, y1, x2, y2])\n",
        "            elif cls == 4:\n",
        "                self.motorcycles.append([x1, y1, x2, y2])\n",
        "            elif cls == 1:\n",
        "                self.cross_walks.append([x1, y1, x2, y2])\n",
        "            elif cls == 6:\n",
        "                self.red_lights.append([x1, y1, x2, y2])"
      ],
      "metadata": {
        "id": "hHFzZcMHBmJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrackerObject:\n",
        "    def __init__(self, tracker_vehicles, tracker, frame):\n",
        "        self.tracker_vehicles = tracker_vehicles\n",
        "        self.tracker = tracker\n",
        "        self.frame = frame\n",
        "\n",
        "    def deep_sort_vehicle(self, vehicle):\n",
        "        tracks_vehicles = self.tracker_vehicles.update_tracks(vehicle, frame=self.frame)\n",
        "        return tracks_vehicles\n",
        "\n",
        "    def deep_sort_dets(self, dets):\n",
        "        tracks = self.tracker.update_tracks(dets, frame=self.frame)\n",
        "        return tracks"
      ],
      "metadata": {
        "id": "iYV2nJLpBl5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HandleTrackVehicles:\n",
        "    def __init__(self, track_vehicles, frame):\n",
        "        self.frame = frame\n",
        "        self.vehicle_info = []\n",
        "        self.track_vehicles = track_vehicles\n",
        "\n",
        "        self.track_id = None\n",
        "        self.bbox = None\n",
        "\n",
        "    def handle_tracks_vehicle(self):\n",
        "        for track_v in self.track_vehicles:\n",
        "            if not track_v.is_confirmed() or track_v.time_since_update > 1:\n",
        "                continue\n",
        "            self.track_id = track_v.track_id\n",
        "            self.bbox = track_v.to_tlbr()\n",
        "            x1_V, y1_V, x2_V, y2_V = map(int, self.bbox)\n",
        "\n",
        "            self.vehicle_info.append({\n",
        "                'track_id': self.track_id,\n",
        "                'bbox': self.bbox\n",
        "            })\n",
        "\n",
        "            Color_Pala(self.frame).draw_color(self.track_id, self.bbox)"
      ],
      "metadata": {
        "id": "sDY4t4qOBlaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Color_Pala():\n",
        "    color_palette = defaultdict(lambda: (\n",
        "        random.randint(0, 255),\n",
        "        random.randint(0, 255),\n",
        "        random.randint(0, 255)\n",
        "    ))\n",
        "\n",
        "    def __init__(self, frame):\n",
        "        self.frame = frame\n",
        "\n",
        "    def draw_color(self, track_id, bounding_box):\n",
        "        x1, y1, x2, y2 = map(int, bounding_box)\n",
        "        color = Color_Pala.color_palette[track_id]\n",
        "        label = f\"ID: {track_id}\"\n",
        "        (text_width, text_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)\n",
        "        cv2.rectangle(self.frame,\n",
        "                (x1, y1),\n",
        "                (x2, y2),\n",
        "                color, 2)\n",
        "        cv2.putText(self.frame, label,\n",
        "                    (int(x1), int(y1) - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)"
      ],
      "metadata": {
        "id": "fpsQYwA1gAir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HandleTracks:\n",
        "    def __init__(self, tracks, vehicle_info, cars, motorcycles,\n",
        "                 license_plates, red_lights, stop_line, frame, vehicle_to_license):\n",
        "        self.tracks = tracks\n",
        "        self.vehicle_info = vehicle_info\n",
        "        self.cars = cars\n",
        "        self.motorcycles = motorcycles\n",
        "        self.license_plates = license_plates\n",
        "        self.red_lights = red_lights\n",
        "        self.stop_line = stop_line\n",
        "        self.frame = frame\n",
        "\n",
        "    def handle_tracks(self):\n",
        "        for track in self.tracks:\n",
        "            if not track.is_confirmed() or track.time_since_update > 1:\n",
        "                continue\n",
        "            track_id_plate = track.track_id\n",
        "            bbox_plate = track.to_tlbr()\n",
        "            x1_L, y1_L, x2_L, y2_L = map(int, bbox_plate)\n",
        "\n",
        "            self.handle_vehicle_list(x1_L, y1_L, x2_L, y2_L)\n",
        "\n",
        "            Color_Pala(self.frame).draw_color(track_id_plate, bbox_plate)\n",
        "\n",
        "    def handle_vehicle_list(self, x1_L, y1_L, x2_L, y2_L):\n",
        "        for vehicle in self.vehicle_info:\n",
        "            track_id_vehicle = vehicle['track_id']\n",
        "            bbox_vehicle = vehicle['bbox']\n",
        "            x1_V_current, y1_V_current, x2_V_current, y2_V_current = map(int, vehicle['bbox'])\n",
        "\n",
        "            if (len(self.cars) > 0 or len(self.motorcycles) > 0) and len(self.license_plates) > 0 and len(self.red_lights) > 0:\n",
        "                if self.stop_line is not None:\n",
        "                    if is_vehicle_crossed_stop_line([x1_V_current, y1_V_current, x2_V_current, y2_V_current], self.stop_line):\n",
        "                        if is_valid_plate_flexible([x1_L, y1_L, x2_L, y2_L], [x1_V_current, y1_V_current, x2_V_current, y2_V_current]):\n",
        "                            crop_img = self._get_cropped_plate(x1_L, y1_L, x2_L, y2_L)\n",
        "\n",
        "                            if track_id_vehicle not in vehicle_to_license:\n",
        "                                vehicle_to_license[track_id_vehicle] = []\n",
        "                            vehicle_to_license[track_id_vehicle].append(crop_img)\n",
        "\n",
        "\n",
        "    def _get_cropped_plate(self, x1_L, y1_L, x2_L, y2_L):\n",
        "        center_x = (x1_L + x2_L) // 2\n",
        "        center_y = (y1_L + y2_L) // 2\n",
        "\n",
        "        x1_pad = max(center_x - 335 // 2, 0)\n",
        "        y1_pad = max(center_y - 462 // 2, 0)\n",
        "        x2_pad = x1_pad + 335\n",
        "        y2_pad = y1_pad + 462\n",
        "\n",
        "        x2_pad = min(x2_pad, frame.shape[1])\n",
        "        y2_pad = min(y2_pad, frame.shape[0])\n",
        "        x1_pad = max(x2_pad - 335, 0)\n",
        "        y1_pad = max(y2_pad - 462, 0)\n",
        "\n",
        "        crop_img = self.frame[y1_pad:y2_pad, x1_pad:x2_pad]\n",
        "\n",
        "        return crop_img\n"
      ],
      "metadata": {
        "id": "WW3PmzS4BlTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import time\n",
        "\n",
        "DISTANCE_THRESHOLD = 10\n",
        "\n",
        "CONFIRMATION_FRAMES = 3\n",
        "tracker = DeepSort(\n",
        "    max_age=10,\n",
        "    nn_budget=50,\n",
        "    n_init=CONFIRMATION_FRAMES,\n",
        ")\n",
        "\n",
        "tracker_vehicles = DeepSort(\n",
        "    max_age=10,\n",
        "    nn_budget=50,\n",
        "    n_init=CONFIRMATION_FRAMES,\n",
        ")\n",
        "\n",
        "\n",
        "video_path = \"/content/4Ly giai chuyen la o TP Vinh đen đo đuoc đi thang tai mot so giao (online-video-cutter.com).mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "width, height, fpbs = (int(cap.get(x)) for x in\n",
        "           (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "out = cv2.VideoWriter('/content/output_video__version_3.avi', fourcc, fpbs,\n",
        "            (width, height))\n",
        "\n",
        "frame_count = 0\n",
        "\n",
        "persistent_crosswalk = None\n",
        "last_crosswalk_time = 0\n",
        "crosswalk_timeout = 1.0\n",
        "\n",
        "vehicle_to_license = {}\n",
        "\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    frame_count +=1\n",
        "\n",
        "    OBJECT_DETECTOR = ObjectDetector(model)\n",
        "    OBJECT_DETECTOR.detect_objects(frame)\n",
        "\n",
        "    TRACKER_OBJECT = TrackerObject(tracker_vehicles, tracker, frame)\n",
        "    TRACKERS_VEHICLES = TRACKER_OBJECT.deep_sort_vehicle(OBJECT_DETECTOR.vehicles)\n",
        "    TRACKERS = TRACKER_OBJECT.deep_sort_dets(OBJECT_DETECTOR.dets)\n",
        "\n",
        "\n",
        "    current_time = time.time()\n",
        "    if len(OBJECT_DETECTOR.cross_walks) > 0:\n",
        "        persistent_crosswalk = OBJECT_DETECTOR.cross_walks[0]\n",
        "        last_crosswalk_time = current_time\n",
        "\n",
        "    stop_line = None\n",
        "    if persistent_crosswalk is not None and (current_time - last_crosswalk_time) < crosswalk_timeout:\n",
        "        stop_line = create_stop_line_from_crosswalk(persistent_crosswalk)\n",
        "        draw_stop_line(frame, stop_line)\n",
        "    else:\n",
        "        persistent_crosswalk = None\n",
        "\n",
        "\n",
        "    height_frame, width_frame = frame.shape[:2]\n",
        "\n",
        "    HANDLE_TRACK_VEHICLES = HandleTrackVehicles(TRACKERS_VEHICLES, frame)\n",
        "    HANDLE_TRACK_VEHICLES.handle_tracks_vehicle()\n",
        "\n",
        "\n",
        "    HANDLE_TRACKS = HandleTracks(TRACKERS, HANDLE_TRACK_VEHICLES.vehicle_info, OBJECT_DETECTOR.cars,\n",
        "                                OBJECT_DETECTOR.motorcycles, OBJECT_DETECTOR.lisence_plates,\n",
        "                                OBJECT_DETECTOR.red_lights, stop_line, frame, vehicle_to_license)\n",
        "\n",
        "    HANDLE_TRACKS.handle_tracks()\n",
        "\n",
        "\n",
        "    for track_id, lisence_img in vehicle_to_license.items():\n",
        "        text_fragments  = []\n",
        "        extract_plates = None\n",
        "        full_text = None\n",
        "\n",
        "        for bbox in lisence_img:\n",
        "            extract_plates = ExtractLicensePlates(bbox)\n",
        "            plate_number = extract_plates.run_method_OCR()\n",
        "            if plate_number:\n",
        "                text_fragments.append(plate_number)\n",
        "            time.sleep(1)\n",
        "\n",
        "        if extract_plates is not None and text_fragments:\n",
        "            full_text = extract_plates.analyze_plates(text_fragments)\n",
        "\n",
        "        (text_width, text_height), _ = cv2.getTextSize(full_text.strip() if full_text else \"UNKNOWN\" ,\n",
        "                                                    cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                                                    1, 2)\n",
        "        cv2.putText(frame, full_text.strip() if full_text else \"UNKNOWN\" ,\n",
        "                        (width_frame - text_width - 20, height_frame - 30),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2, cv2.LINE_AA)\n",
        "\n",
        "        print(full_text)\n",
        "\n",
        "    out.write(frame)\n",
        "\n",
        "cap.release()\n",
        "out.release()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "08heaFSM14Lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TTE7dEdH5ucd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 7048913,
          "sourceId": 11275378,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30918,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}